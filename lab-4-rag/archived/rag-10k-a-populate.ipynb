{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sujee/mongodb-atlas-vector-search/blob/main/lab-4-rag/rag-10k-a-populate.ipynb)\n",
    "\n",
    "#  RAG-1A - Doing RAG with MongoDB\n",
    "\n",
    "## Overview \n",
    "\n",
    "Here is overall RAG pipeline.  In this notebook we will do step-1\n",
    "\n",
    "- ðŸ‘‰ Load PDF documents\n",
    "- Use embedding models to calculate embeddings for PDF documents\n",
    "- Upload them into Atlas\n",
    "- Then query these PDF documents\n",
    "\n",
    "![](https://raw.githubusercontent.com/sujee/mongodb-atlas-vector-search/main/images/rag-1.svg)\n",
    "\n",
    "### What you need to run this notebook\n",
    "\n",
    "- a (free) MongoDB Atlas Account\n",
    "- and connection credentials\n",
    "\n",
    "### The Stack\n",
    "\n",
    "- Langugage : Python\n",
    "- Vector database: Atlas\n",
    "- Embedding Model: \n",
    "\n",
    "\n",
    "### How to run\n",
    "\n",
    "This notebook can be run on Google Colab and stand alone python development environments.  Click here to run on colab.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sujee/mongodb-atlas-vector-search/blob/main/lab-4-rag/rag-10k-a-populate.ipynb)\n",
    "\n",
    "\n",
    "References\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-1: Setup Atlas\n",
    "\n",
    "We will need to have Atlas setup.\n",
    "\n",
    "Follow [instructions here](https://github.com/sujee/mongodb-atlas-vector-search/blob/main/lab-1-atlas-setup/setup-atlas.md)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-: Configuration\n",
    "\n",
    "We need to configure the following\n",
    "- Atlas connection credentials\n",
    "\n",
    "### Option 3A - If running on Colab\n",
    "\n",
    "- Click on 'Colab secrets' icon (ðŸ”‘) on left pane, and crate the following secrets.\n",
    "- `ATLAS_URI` and `OPENAI_API_KEY`\n",
    "-  Make sure the `notebook access` button is checked on for both\n",
    "- See screenshot below for example\n",
    "\n",
    "<!-- ![](../images/colab-secret-2.png) -->\n",
    "\n",
    "![](https://raw.githubusercontent.com/sujee/mongodb-atlas-vector-search/main/images/colab-secret-1.png)\n",
    "\n",
    "\n",
    "### Option 3B - If running on local python environment\n",
    "\n",
    "- setup your local python env following this [setup guide](https://github.com/sujee/mongodb-atlas-vector-search/blob/main/setup-python-env.md)\n",
    "- Create a file named `.env` in the same location as notebook\n",
    "- And add the following settings\n",
    "\n",
    "```text\n",
    "ATLAS_URI=mongodb+srv://<username>:<password>@sandbox.....\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-?: Determine Runtime Environment\n",
    "\n",
    "This code will figure out if we are running on Google Colab environment or local environment.  We use it to install relevant packages later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will keep all global variables in an object to not pollute the global namespace.\n",
    "class MyConfig(object):\n",
    "    pass\n",
    "\n",
    "MY_CONFIG = MyConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# are we running in Colab?\n",
    "import os\n",
    "\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    print(\"Running in Colab\")\n",
    "    MY_CONFIG.RUNNING_IN_COLAB = True\n",
    "else:\n",
    "    print(\"NOT running in Colab\")\n",
    "    MY_CONFIG.RUNNING_IN_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-4: Install dependencies (if necessary)\n",
    "\n",
    "We will install required libraries in cloud environments like Google Colab.  For local environments, we assume the dependencies are already setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MY_CONFIG.RUNNING_IN_COLAB:\n",
    "    !pip install \\\n",
    "                openai==1.13.3 \\\n",
    "                pymongo==4.6.2 \\\n",
    "                llama-index==0.10.17 \\\n",
    "                transformers==4.38.2 \\\n",
    "                sentence_transformers==2.5.1 \\\n",
    "                torch==2.2.1 \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-2: Basic Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Check if we have GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using CUDA/GPU:  True\n",
      "device  0 NVIDIA GeForce RTX 2070\n"
     ]
    }
   ],
   "source": [
    "## Check if GPU is enabled\n",
    "import os\n",
    "import torch\n",
    "\n",
    "## To disable GPU and experiment, uncomment the following line\n",
    "## Normally, you would want to use GPU, if one is available.\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "print (\"using CUDA/GPU: \", torch.cuda.is_available())\n",
    "\n",
    "for i in range(torch.cuda.device_count()):\n",
    "   print(\"device \", i , torch.cuda.get_device_properties(i).name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Logging and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup logging.  To see more loging set the level to DEBUG\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "this_dir = os.path.abspath('')\n",
    "parent_dir = os.path.dirname(this_dir)\n",
    "sys.path.append (os.path.abspath (parent_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-1: Inspect the Documents\n",
    "\n",
    "We are going to be using 10K filings - these are financial documents filed by US public companies to SEC (Securities and Exchange Commission).  You can read about them [here](https://www.investor.gov/introduction-investing/investing-basics/glossary/form-10-k)\n",
    "\n",
    "We have two 10k documents from Lyft and Uber\n",
    "\n",
    "```text\n",
    "data/10k\n",
    "â”œâ”€â”€ lyft_2021.pdf\n",
    "â””â”€â”€ uber_2021.pdf\n",
    "```\n",
    "\n",
    "Don't think it is just 2 documents.  Each PDF documnet is about 200+ pages long.  So these are serious PDF documents.\n",
    "\n",
    "Go ahead and inspect the documents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-2: Load Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "## Load Settings from .env file\n",
    "from dotenv import find_dotenv, dotenv_values\n",
    "\n",
    "# _ = load_dotenv(find_dotenv()) # read local .env file\n",
    "config = dotenv_values(find_dotenv())\n",
    "\n",
    "# debug\n",
    "# print (config)\n",
    "\n",
    "ATLAS_URI = config.get('ATLAS_URI')\n",
    "\n",
    "if not ATLAS_URI:\n",
    "    raise Exception (\"'ATLAS_URI' is not set.  Please set it above to continue...\")\n",
    "\n",
    "## Only need this if we are using OpenAI for Embeddings\n",
    "# OPENAI_API_KEY = config.get(\"OPENAI_API_KEY\")\n",
    "# if not OPENAI_API_KEY:\n",
    "#     raise Exception (\"'OPENAI_API_KEY' is not set.  Please set it above to continue...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_NAME = 'rag1'\n",
    "COLLECTION_NAME = '10k'\n",
    "INDEX_NAME = 'idx_embedding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "## LlamaIndex will download embeddings models as needed.\n",
    "## Set llamaindex cache dir to ./cache dir here (Default is system tmp)\n",
    "## This way, we can easily see downloaded artifacts\n",
    "os.environ['LLAMA_INDEX_CACHE_DIR'] = os.path.join(os.path.abspath(''), '..', 'llama-index-cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atlas client initialized\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "\n",
    "mongodb_client = pymongo.MongoClient(ATLAS_URI)\n",
    "\n",
    "print (\"Atlas client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-3: Clear out the collection\n",
    "\n",
    "For a fresh start!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document count before delete : 0\n",
      "Deleted docs : 0\n"
     ]
    }
   ],
   "source": [
    "database = mongodb_client[DB_NAME]\n",
    "collection = database [COLLECTION_NAME]\n",
    "\n",
    "doc_count = collection.count_documents (filter = {})\n",
    "print (f\"Document count before delete : {doc_count:,}\")\n",
    "\n",
    "result = collection.delete_many(filter= {})\n",
    "print (f\"Deleted docs : {result.deleted_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-4: Setup Embeddings\n",
    "\n",
    "The default embedding is OpenAI.  We can always plugin custom embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 - Option A - OpenAI Embeddings\n",
    "\n",
    "This is using OpenAI embedding model\n",
    "You will need an API key (defined in env variable : OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index import  OpenAIEmbedding\n",
    "# embed_model = OpenAIEmbedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 - Option B : Using Custom Embeddings\n",
    "\n",
    "Here are a select models for comparison.  Taken from leaderboard : https://huggingface.co/spaces/mteb/leaderboard\n",
    "\n",
    "| model name                              | overall score | model size | model params | embedding length | License  | url                                                            |\n",
    "|-----------------------------------------|---------------|------------|--------------|------------------|----------|----------------------------------------------------------------|\n",
    "| BAAI/bge-large-en-v1.5                  | 64.x          | 1.34 GB    | 335 M        | 1024             | MIT      | https://huggingface.co/BAAI/bge-large-en-v1.5                  |\n",
    "| BAAI/bge-small-en-v1.5                  | 62.x          | 133 MB     | 33.5 M       | 384              | MIT      | https://huggingface.co/BAAI/bge-small-en-v1.5                  |\n",
    "| sentence-transformers/all-mpnet-base-v2 | 57.8          | 438 MB     |              | 768              | Apache 2 | https://huggingface.co/sentence-transformers/all-mpnet-base-v2 |\n",
    "| sentence-transformers/all-MiniLM-L12-v2 | 56.x          | 134 MB     |              | 384              | Apache 2 | https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2 |\n",
    "| sentence-transformers/all-MiniLM-L6-v2  | 56.x          | 91 MB      |              | 384              | Apache 2 | https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sujee/anaconda3/envs/atlas-2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings import HuggingFaceEmbedding\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is explicitly disabled. Using MockLLM.\n"
     ]
    }
   ],
   "source": [
    "## setup embed model\n",
    "\n",
    "# The LLM used to generate natural language responses to queries.\n",
    "# If not provided, defaults to gpt-3.5-turbo from OpenAI\n",
    "# If your OpenAI key is not set, defaults to llama2-chat-13B from Llama.cpp\n",
    "# We don't need an LLM just yet, so setting it to None\n",
    "\n",
    "from llama_index import  ServiceContext\n",
    "\n",
    "service_context = ServiceContext.from_defaults(embed_model=embed_model, llm=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-5: Connect Illama-Index and MongoDB Atlas\n",
    "\n",
    "Let's define MongoDB Atlas as our vector storage. This is critical to stored indexed data and then query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.mongodb import MongoDBAtlasVectorSearch\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "\n",
    "\n",
    "vector_store = MongoDBAtlasVectorSearch(mongodb_client = mongodb_client,\n",
    "                                 db_name = DB_NAME, collection_name = COLLECTION_NAME,\n",
    "                                 index_name  = 'idx_embedding',\n",
    "                                 ## the following columns are set to default values\n",
    "                                 # embedding_key = 'embedding', text_key = 'text', metadata_= 'metadata',\n",
    "                                 )\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-6: Read PDF Documents\n",
    "\n",
    "Ilmaa-index has very handy `SimpleDirectoryReader` that can read single files / multiple files / or entire directory content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 545 chunks from '../data/10k/'\n",
      "CPU times: user 10.3 s, sys: 34.7 ms, total: 10.4 s\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llama_index.readers.file.base import SimpleDirectoryReader\n",
    "\n",
    "data_dir = '../data/10k/'\n",
    "\n",
    "## This reads one doc\n",
    "# docs = SimpleDirectoryReader(\n",
    "#     input_files=[\"./data/10k/uber_2021.pdf\"]\n",
    "# ).load_data()\n",
    "\n",
    "## here we read entire directory content\n",
    "docs = SimpleDirectoryReader(\n",
    "        input_dir=data_dir\n",
    ").load_data()\n",
    "\n",
    "print (f\"Loaded {len(docs)} chunks from '{data_dir}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-7: Index the docs and Store them into MongoDB Atlas\n",
    "\n",
    "When we execute the code below, the following will happen\n",
    "\n",
    "- documents are indexed\n",
    "- embeddings are created for text\n",
    "- the document (text, embeddings) are stored in our Vector Storage (MongoDB Atlas in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.5 s, sys: 375 ms, total: 10.9 s\n",
      "Wall time: 15.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llama_index.indices.vector_store.base import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    docs, storage_context=storage_context,\n",
    "    service_context=service_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-8: Verify Created Documents in Atlas\n",
    "\n",
    "- Go to your Atlas dashboard\n",
    "- Select 'browse collections' \n",
    "- Select database: `rag1`  and collection `10k`\n",
    "- Click around to see some sample data inserted\n",
    "- You will see `text` attribute having text data \n",
    "- `embeddings` are populated too\n",
    "- expand the `meta` attribute.  This is automatically populated for us by llama-index\n",
    "\n",
    "![](../images/10k-documents-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-9: Setup Vector Index\n",
    "\n",
    "Before we do vector search, we need to define an embedding index\n",
    "\n",
    "You can look at steps here [setup-atlas-index.md](setup-atlas-index.md)\n",
    "\n",
    "Here are the details:\n",
    "\n",
    "index_name = **'idx_embedding'**\n",
    "\n",
    "index defitintion json\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"type\": \"vector\",\n",
    "      \"path\": \"embedding\",\n",
    "      \"numDimensions\": 384,\n",
    "      \"similarity\": \"dotProduct\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "The similarity function can be  one of \n",
    "- \"euclidean\"\n",
    "- \"cosine\"\n",
    "- \"dotProduct\"\n",
    "\n",
    "\n",
    "### Follow these steps to setup index\n",
    "\n",
    "\n",
    "![](../images/atlas-index-2.png)\n",
    "\n",
    "![](../images/atlas-index-7.png)\n",
    "\n",
    "![](../images/atlas-index-8.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are done \n",
    "\n",
    "Now the data is populated and ready to be queried.\n",
    "\n",
    "Let's go to the next lab: query"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atlas-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
